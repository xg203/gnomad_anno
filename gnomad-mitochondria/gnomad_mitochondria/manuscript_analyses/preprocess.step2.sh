# preprocess step 2: preprocess data on 70K samples (before any sample filtering)
#
# I have always run this with lots of memory using uger shell command: ish -l h_vmem=30g

##############################################################
# Input files:
# A)  files generated by preprocess.step1.sh files
# A1) ./sample_annotations_gnomad.txt
# A2) ./summary.var.txt
#
# B)  raw data on unfiltered samples/variants from Kristen's directory 
# B1) $SOURCE_DIR/combined_new_run.vcf.bgz
# B2) $SOURCE_DIR/unfiltered_samples/unfiltered_sample_annotations.txt
# B3) $SOURCE_DIR/insert_size_metrics.txt: tab-del file from Kristen with the median insert size for each sample
# B4) $SOURCE_DIR/vep_unfiltered.vcf.bgz
#
# C)  additional annotation files created by Sarah/Kristen
# C1) numtAB.txt: tab-del file of validated NUMT-FPs
#
# D)  scripts
# D1) ./vcf_to_table.nosplit.pl
# D2) ./merge_sets.pl
##############################################################



##############################################################
# get raw data for unfiltered variants, unfiltered samples, and VEP annotations
##############################################################
cp $SOURCE_DIR/combined_new_run.vcf.bgz zcombined_unfiltered.vcf.gz 
cp $SOURCE_DIR/unfiltered_samples/unfiltered_sample_annotations.txt .
cp $SOURCE_DIR/insert_size_metrics.txt

gunzip zcombined_unfiltered.vcf.gz 
# change header mito_cn to mtCN
perl -i.bak -p -e 's/mito_cn/mtCN/g' unfiltered_sample_annotations.txt

# VEP annotations
cp $SOURCE_DIR/vep_unfiltered.vcf.bgz vep_unfiltered.vcf.gz 
gunzip vep_unfiltered.vcf.gz 

############################################
# convert from vcf into sample2var format for non-zero values
############################################
# this excludes variants that were never pass

./vcf_to_table.nosplit.pl -pass 6 -m 0.0001 -dpcol 0 -vafcol 1 -filtercol 4 zcombined_unfiltered.vcf > all.sample2var.unfiltered.noannot.txt

############################################
# Add 2 annotations to unfiltered_sample_annotations.annot.txt (file has 1 line per sample):
#   release.3.1: "true" if sample included in final release
#   median_insert_size: median insert size of sample (generated from WGS metrics tool I think)
# This file has one line per sample
############################################

# add to sample file an annotation of which samples are included in final release
cut -f 1-2 sample_annotations_gnomad.txt | perl -p -e 's/\t(.*)$/\t$1\ttrue/g' | perl -p -e 's/s\tparticipant_id\ttrue/sample_id\tparticipant_id\trelease3.1.1/g' > tmp.release_samples.txt
./merge_sets.pl -header -byname -x tmp.release_samples.txt=participant_id,participant_id,release3.1.1 unfiltered_sample_annotations.txt > unfiltered_sample_annotations.annot.txt

# add in insert size from file Kristen created for me from metadata
./merge_sets.pl -header -x insert_size_metrics.txt=0,0,2 unfiltered_sample_annotations.annot.txt > tmp
mv tmp unfiltered_sample_annotations.annot.txt

############################################
# File all.sample2var.unfiltered.noannot.txt: file has 1 line per sample-variant
# Add the following 4 annotation columns:
# 1) hap_defining_variant : blank or hap_defining_variant (if known haplogroup variant)
# 2) numtID : blank or numtA or numtB based on PacBio validateion
# 3) release3.1.1 : blank or true (if sample in final release set)
# 4) mtCN : mtDNA copy number of sample
#
# to do this we merge in the columns we want from other files
# note the first column in SAMPLE_ID (with special characters eg spaces, colons) but need to merge via participant_id (no special characters)
#
############################################

cp all.sample2var.unfiltered.noannot.txt tmp1.txt
cut -f 1 all.sample2var.unfiltered.noannot.txt > t1
./merge_sets.pl -header -byname -x unfiltered_sample_annotations.annot.txt=SAMPLE_ID,s,participant_id t1 | cut -f 2 > t1.remap
cut -f 2-5 all.sample2var.unfiltered.noannot.txt > t2
paste t1.remap t2 > tmp1.txt
./merge_sets.pl -header -byname -x ./summary.var.txt=POS.REF.ALT,POS.REF.ALT,hap_defining_variant tmp1.txt > tmp2.txt
mv tmp2.txt tmp1.txt
./merge_sets.pl -header -byname -x numtAB.txt=POS.REF.ALT,variant,numtID tmp1.txt > tmp2.txt
mv tmp2.txt tmp1.txt
./merge_sets.pl -header -byname -x tmp.release_samples.txt=participant_id,participant_id,release3.1.1 tmp1.txt > tmp2.txt
mv tmp2.txt tmp1.txt
./merge_sets.pl -header -byname -x unfiltered_sample_annotations.txt=participant_id,participant_id,mtCN tmp1.txt > all.sample2var.unfiltered.txt

############################################
# Now create passplus 
# which ignores these filters: low_allele_frac|mt_many_low_hets|possible_numt
# but gets rid of other FAIL filters
############################################

cat all.sample2var.unfiltered.txt | grep -v -P "(base_qual|position|strand_bias|weak_evidence|contamination)" > all.sample2var.passplus.txt

################################################
# convert vep_unfiltered.vcf into tab-del summary.unfiltered.var.vep.txt
############################################
grep -v "^\#\#" vep_unfiltered.vcf | cut -f 1-8 | perl -p -e 's/^(\S+)\t(\S+)\t(\S+)\t(\S+)\t(\S+)\t(\S+)\t(\S+)\t/$2\.$4\.$5\t$7\t/g' | perl -p -e 's/\t[^\t]*CSQ=([^;]+).*$/\t$1/g' | perl -p -e 's/INFO/Allele|Consequence|IMPACT|SYMBOL|Gene|Feature_type|Feature|BIOTYPE|EXON|INTRON|HGVSc|HGVSp|cDNA_position|CDS_position|Protein_position|Amino_acids|Codons|ALLELE_NUM|DISTANCE|STRAND|VARIANT_CLASS|MINIMISED|SYMBOL_SOURCE|HGNC_ID|CANONICAL|TSL|APPRIS|CCDS|ENSP|SWISSPROT|TREMBL|UNIPARC|GENE_PHENO|SIFT|PolyPhen|DOMAINS|HGVS_OFFSET|MOTIF_NAME|MOTIF_POS|HIGH_INF_POS|MOTIF_SCORE_CHANGE|LoF|LoF_filter|LoF_flags|LoF_info/g' | perl -p -e 's/\|/\t/g' | cut -f 1-10 > summary.unfiltered.var.vep.txt

